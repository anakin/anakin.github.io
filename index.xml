<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Anakin- 奔向NB的生活</title>
    <link>http://anakin.github.io/</link>
    <description>Recent content on Anakin- 奔向NB的生活</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en</language>
    <lastBuildDate>Sun, 19 May 2019 22:52:01 +0800</lastBuildDate>
    
        <atom:link href="http://anakin.github.io/index.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title>Etcd实现MVCC的原理</title>
      <link>http://anakin.github.io/post/etcd-mvcc/</link>
      <pubDate>Sun, 19 May 2019 22:52:01 +0800</pubDate>
      
      <guid>http://anakin.github.io/post/etcd-mvcc/</guid>
      
        <description>

&lt;p&gt;etcd满足的是CAP理论中的CP，实现了最终的强一致，使用Raft协议，Quorum机制（大多数同意原则）,&lt;/p&gt;

&lt;h2 id=&#34;mvcc的意思&#34;&gt;MVCC的意思&lt;/h2&gt;

&lt;p&gt;Multi-Version Concurrency Control 多版本并发控制，目的是为了实现并发访问&lt;/p&gt;

&lt;h2 id=&#34;实现原理&#34;&gt;实现原理&lt;/h2&gt;

&lt;p&gt;在etcd中，MVCC是如何实现的呢，先来看一下相关的代码：&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;type revision struct {
main int64
sub int64
} 

type generation struct {
ver     int64
created revision 
revs    []revision
} 

type keyIndex struct {
key         []byte
modified    revision 
generations []generation
} 
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;根据代码，可以看出：
* 每个tx事务有唯一事务ID，在etcd中叫做main ID，全局递增不重复。
* 一个tx可以包含多个修改操作（put和delete），每一个操作叫做一个revision（修订），共享同一个main ID。
* 一个tx内连续的多个修改操作会被从0递增编号，这个编号叫做sub ID。
* 每个revision由（main ID，sub ID）唯一标识。
* 多个版本的修改历史，保存在generations中&lt;/p&gt;

&lt;p&gt;每一次操作行为都被单独记录下来，用户value保存到bbolt中。&lt;/p&gt;

&lt;p&gt;在bbolt中，每个revision将作为key，即序列化（revision.main+revision.sub）作为key。因此，我们先通过内存btree在keyIndex.generations[0].revs中找到最后一条revision，即可去bbolt中读取对应的数据。&lt;/p&gt;

&lt;p&gt;相应的，etcd支持按key前缀查询，其实也就是遍历btree的同时根据revision去bbolt中获取用户的value。&lt;/p&gt;

&lt;p&gt;总结一下就是，内存btree维护的是用户key =&amp;gt; keyIndex的映射，keyIndex内维护多版本的revision信息，而revision可以映射到磁盘bbolt中的用户value。&lt;/p&gt;
</description>
      
    </item>
    
    <item>
      <title>Redis持久化</title>
      <link>http://anakin.github.io/post/redis-rdb-aof/</link>
      <pubDate>Fri, 17 May 2019 13:22:22 +0800</pubDate>
      
      <guid>http://anakin.github.io/post/redis-rdb-aof/</guid>
      
        <description>

&lt;p&gt;redis的持久化有两种方式，RDB和AOF
 ## RDB:
在指定的时间间隔内，执行指定次数的写操作，则会将内存中的数据写入到磁盘中。即在指定目录下生成一个dump.rdb文件。Redis 重启会通过加载dump.rdb文件恢复数据。&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;p&gt;配置方法：&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;save 900 1
save 300 10
save 60 10000
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;意思是， 900秒内有1个更改，300秒内有10个更改以及60秒内有10000个更改，则将内存中的数据快照写入磁盘。&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;恢复方法&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;将dump.rdb 文件拷贝到redis的安装目录的bin目录下，重启redis服务即可&lt;/p&gt;

&lt;h2 id=&#34;aof&#34;&gt;AOF&lt;/h2&gt;

&lt;p&gt;采用日志的形式来记录每个写操作，并追加到文件中。Redis 重启的会根据日志文件的内容将写指令从前到后执行一次以完成数据的恢复工作。&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;p&gt;配置方法&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;appendonly yes
appendfilename &amp;quot;appendonly.aof&amp;quot;
#指定更新条件
# appendfsync always
appendfsync everysec
# appendfsync no
#配置重写触发机制
auto-aof-rewrite-percentage 100
auto-aof-rewrite-min-size 64mb
&lt;/code&gt;&lt;/pre&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;恢复方法&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;将appendonly.aof 文件拷贝到redis的安装目录的bin目录下，重启redis服务即可。如果因为某些原因导致appendonly.aof 文件格式异常，从而导致数据还原失败，可以通过命令redis-check-aof &amp;ndash;fix appendonly.aof 进行修复&lt;/p&gt;

&lt;h2 id=&#34;区别&#34;&gt;区别&lt;/h2&gt;

&lt;p&gt;RDB通过fork的方式进行处理，性能更好
AOF备份所有的操作，数据更完整，但是效率略差，文件相对较大
实际环境中，可以两者同时使用&lt;/p&gt;
</description>
      
    </item>
    
    <item>
      <title>Golang利用redis实现分布式锁</title>
      <link>http://anakin.github.io/post/golang-redis-lock/</link>
      <pubDate>Thu, 16 May 2019 20:11:09 +0800</pubDate>
      
      <guid>http://anakin.github.io/post/golang-redis-lock/</guid>
      
        <description>

&lt;h2 id=&#34;原理&#34;&gt;原理&lt;/h2&gt;

&lt;p&gt;使用SETNX命令(SET if Not eXists)&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;SETNX key value
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;将 key 的值设为 value，当且仅当 key 不存在。若给定的 key 已经存在，则 SETNX 不做任何动作。&lt;/p&gt;

&lt;p&gt;设置成功，返回 1 。&lt;/p&gt;

&lt;p&gt;设置失败，返回 0 。&lt;/p&gt;

&lt;p&gt;为防止获取锁之后，忘记删除，成功后再设置一个过期时间&lt;/p&gt;

&lt;p&gt;以上就是利用redis实现分布式锁的原理&lt;/p&gt;

&lt;h2 id=&#34;代码&#34;&gt;代码&lt;/h2&gt;

&lt;pre&gt;&lt;code&gt;package main

import (
	&amp;quot;fmt&amp;quot;
	&amp;quot;github.com/gomodule/redigo/redis&amp;quot;
	&amp;quot;log&amp;quot;
	&amp;quot;time&amp;quot;
)

type Lock struct {
	resource string
	token    string
	conn     redis.Conn
	timeout  int
}

func (lock *Lock) tryLock() (ok bool, err error) {
	_, err = redis.String(lock.conn.Do(&amp;quot;SET&amp;quot;, lock.key(), lock.token, &amp;quot;EX&amp;quot;, int(lock.timeout), &amp;quot;NX&amp;quot;))
	if err == redis.ErrNil {
		return false, nil
	}
	if err != nil {
		return false, err
	}
	return true, nil
}
func (lock *Lock) Unlock() (err error) {
	_, err = lock.conn.Do(&amp;quot;del&amp;quot;, lock.key())
	return
}

func (lock *Lock) key() string {
	return fmt.Sprintf(&amp;quot;redislock:%s&amp;quot;, lock.resource)
}

func (lock *Lock) AddTimeout(ex_time int64) (ok bool, err error) {
	ttl_time, err := redis.Int64(lock.conn.Do(&amp;quot;TTL&amp;quot;, lock.key()))
	fmt.Println(ttl_time)
	if err != nil {
		log.Fatal(err)
	}
	if ttl_time &amp;gt; 0 {
		fmt.Println(11)
		_, err := redis.String(lock.conn.Do(&amp;quot;SET&amp;quot;, lock.key(), lock.token, &amp;quot;EX&amp;quot;, int(ttl_time+ex_time)))
		if err == redis.ErrNil {
			return false, nil
		}
		if err != nil {
			return false, err
		}
	}
	return false, nil
}

func TryLock(conn redis.Conn, resource string, token string, DefaultTimeout int) (lock *Lock, ok bool, err error) {
	return TryLockWithTimeout(conn, resource, token, DefaultTimeout)
}

func TryLockWithTimeout(conn redis.Conn, resource string, token string, timeout int) (lock *Lock, ok bool, err error) {
	lock = &amp;amp;Lock{resource: resource, token: token, conn: conn, timeout: timeout}
	ok, err = lock.tryLock()
	if !ok || err != nil {
		lock = nil
	}
	return
}

func main() {
	fmt.Println(&amp;quot;start&amp;quot;)
	DefaultTimeout := 10
	conn, err := redis.Dial(&amp;quot;tcp&amp;quot;, &amp;quot;localhost:6379&amp;quot;)
	if err != nil {
		log.Fatal(err)
	}
	lock, ok, err := TryLock(conn, &amp;quot;anakin.sun&amp;quot;, &amp;quot;token&amp;quot;, int(DefaultTimeout))
	if err != nil {
		log.Fatal(&amp;quot;error lock&amp;quot;)
	}
	if !ok {
		log.Fatal(&amp;quot;lock fail&amp;quot;)
	}
	lock.AddTimeout(100)
	time.Sleep(time.Duration(DefaultTimeout) * time.Second)
	fmt.Println(&amp;quot;end&amp;quot;)
	defer lock.Unlock()
}
&lt;/code&gt;&lt;/pre&gt;
</description>
      
    </item>
    
    <item>
      <title>TCP协议细节学习</title>
      <link>http://anakin.github.io/post/tcp-detail/</link>
      <pubDate>Tue, 14 May 2019 12:34:43 +0800</pubDate>
      
      <guid>http://anakin.github.io/post/tcp-detail/</guid>
      
        <description>

&lt;h2 id=&#34;tcp协议中包含ip信息么&#34;&gt;TCP协议中包含ip信息么&lt;/h2&gt;

&lt;p&gt;TCP协议中并不包含ip信息，ip信息是在第三层处理的，TCP中处理的是端口信息&lt;/p&gt;

&lt;h2 id=&#34;mss的值是如何计算的&#34;&gt;MSS的值是如何计算的&lt;/h2&gt;

&lt;p&gt;TCP协议中可选的MSS（Maximum Segment Size，最大报文长度））参数，一般使用MTU代替，值为1460。这个值是怎么来的呢？
Maximum Transmission Unit，缩写MTU，中文名是：最大传输单元。
假设MTU值和IP数据包大小一致，一个IP数据包的大小是：65535，那么加上以太网帧头和为，一个以太网帧的大小就是：65535 + 14 + 4 = 65553，看起来似乎很完美，发送方也不需要拆包，接收方也不需要重组。
那么假设我们现在的带宽是：100Mbps，因为以太网帧是传输中的最小可识别单元，再往下就是0101所对应的光信号了，所以我们的一条带宽同时只能发送一个以太网帧。如果同时发送多个，那么对端就无法重组成一个以太网帧了，在100Mbps的带宽中（假设中间没有损耗），我们计算一下发送这一帧需要的时间：&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;( 65553 * 8 ) / ( 100 * 1024 * 1024 ) ≈ 0.005(s)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;在100M网络下传输一帧就需要5ms，也就是说这5ms其他进程发送不了任何数据。如果是早先的电话拨号，网速只有2M的情况下：&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;( 65553 * 8 ) / ( 2 * 1024 * 1024 ) ≈ 0.100(s)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;100ms，这简直是噩梦。其实这就像红绿灯，时间要设置合理，交替通行，不然同一个方向如果一直是绿灯，那么另一个方向就要堵成翔了。
既然大了不行，那设置小一点可以么？
假设MTU值设置为100，那么单个帧传输的时间，在2Mbps带宽下需要：&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;( 100 * 8 ) / ( 2 * 1024 * 1024 ) * 1000 ≈ 5(ms)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;时间上已经能接受了，问题在于，不管MTU设置为多少，以太网头帧尾大小是固定的，都是14 + 4，所以在MTU为100的时候，一个以太网帧的传输效率为：&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;( 100 - 14 - 4 ) / 100 = 82%
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;写成公式就是：( T - 14 - 4 ) / T，当T趋于无穷大的时候，效率接近100%，也就是MTU的值越大，传输效率最高，但是基于上一点传输时间的问题，来个折中的选择吧，既然头加尾是18，那就凑个整来个1500，总大小就是1518，传输效率：&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;1500 / 1518 =  98.8%
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;100Mbps传输时间：&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;( 1518 * 8 ) / ( 100 * 1024 * 1024 ) * 1000 = 0.11(ms)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;2Mbps传输时间：&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;( 1518 * 8 ) / ( 2 * 1024 * 1024 ) * 1000 = 5.79(ms)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;总体上时间都还能接受
因此，1500，是一个折中的结果而已，这就是为啥路由器上一般都设置成这个值。
另外，如果使用PPPoE协议（ADSL）,就需要设置成更小的值，为啥呢，。
PPPoE协议头信息为:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;| VER(4bit) | TYPE(4bit) | CODE(8bit) | SESSION-ID(16bit) | LENGTH(16bit) |
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;这里总共是48位，也就是6个字节，那么另外2个字节是什么呢？答案是PPP协议的ID号，占用两个字节，所以在PPPoE环境下，最佳MTU值应该是：1500 - 4 - 2 = 1492
说回来，MTU的值的计算，需要从1500中减去IP数据包包头的大小20Bytes和TCP数据段的包头20Bytes，最后就得到了1460。&lt;/p&gt;

&lt;h2 id=&#34;四次挥手的原因&#34;&gt;四次挥手的原因&lt;/h2&gt;

&lt;p&gt;TCP连接是全双工的，即一端接收到FIN报时，对端虽然不再能发送数据，但是可以接收数据，所以需要两边都关闭连接才算完全关闭了这条TCP连接。&lt;/p&gt;

&lt;h2 id=&#34;time-wait状态&#34;&gt;TIME-WAIT状态&lt;/h2&gt;

&lt;p&gt;主动关闭的一方收到对端发出的FIN报之后，就从FIN-WAIT-2状态切换到TIME-WAIT状态了，再等待2MSL时间才再切换到CLOSED状态。这么做的原因在于：&lt;/p&gt;

&lt;p&gt;确保被动关闭的一方有足够的时间收到ACK，如果没有收到会触发重传。
有足够的时间，以让该连接不会与后面的连接混在一起。
TIME-WAIT状态如果过多，会占用系统资源。Linux下有几个参数可以调整TIME-WAIT状态时间：&lt;/p&gt;

&lt;p&gt;net.ipv4.tcp_tw_reuse = 1 表示开启重用。允许将TIME-WAIT sockets重新用于新的TCP连接，默认为0，表示关闭。&lt;/p&gt;

&lt;p&gt;net.ipv4.tcp_tw_recycle = 1 表示开启TCP连接中TIME-WAIT sockets的快速回收，默认为0，表示关闭。&lt;/p&gt;

&lt;p&gt;net.ipv4.tcp_max_tw_buckets = 5000表示系统同时保持TIME_WAIT套接字的最大数量，如果超过这个数字，TIME_WAIT套接字将立刻被清除并打印警告信息。默认为180000，改为5000。&lt;/p&gt;

&lt;p&gt;然而，从TCP状态转换图可以看出，主动进行关闭的链接才会进入TIME-WAIT状态，所以最好的办法：尽量不要让服务器主动关闭链接，除非一些异常情况，如客户端协议错误、客户端超时等等。&lt;/p&gt;
</description>
      
    </item>
    
    <item>
      <title>Golang的GC学习</title>
      <link>http://anakin.github.io/post/golang-gc/</link>
      <pubDate>Sun, 12 May 2019 23:05:48 +0800</pubDate>
      
      <guid>http://anakin.github.io/post/golang-gc/</guid>
      
        <description>

&lt;h2 id=&#34;stw触发的时间&#34;&gt;STW触发的时间&lt;/h2&gt;

&lt;p&gt;一次GC有两次触发STW，一次是GC的开始阶段，主要是开启写屏障和辅助GC等操作
另外就是表记完成之后，重新扫描部分根对象，禁用写屏障&lt;/p&gt;

&lt;h2 id=&#34;gc的触发条件&#34;&gt;GC的触发条件&lt;/h2&gt;

&lt;p&gt;GC在满足一定条件后会被触发, 触发条件有以下几种:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;gcTriggerAlways: 强制触发GC&lt;/li&gt;
&lt;li&gt;gcTriggerHeap: 当前分配的内存达到一定值就触发GC&lt;/li&gt;
&lt;li&gt;gcTriggerTime: 当一定时间没有执行过GC就触发GC&lt;/li&gt;
&lt;li&gt;gcTriggerCycle: 要求启动新一轮的GC, 已启动则跳过, 手动触发GC的runtime.GC()会使用这个条件&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&#34;三色标记的过程&#34;&gt;三色标记的过程&lt;/h2&gt;

&lt;ul&gt;
&lt;li&gt;所有对象最开始都是白色。&lt;/li&gt;
&lt;li&gt;从 root 开始找到所有可达对象，标记为灰色，放入待处理队列。&lt;/li&gt;
&lt;li&gt;遍历灰色对象队列，将其引用对象标记为灰色放入待处理队列，自身标记为黑色。&lt;/li&gt;
&lt;li&gt;处理完灰色对象队列，执行清扫工作。&lt;/li&gt;
&lt;/ul&gt;
</description>
      
    </item>
    
  </channel>
</rss>
